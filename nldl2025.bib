@proceedings{nldl2025,
  title={Proceedings of the 6th Northern Lights Deep Learning Conference (NLDL)},
  booktitle={Proceedings of the 6th Northern Lights Deep Learning Conference (NLDL)},
  name={Northern Lights Deep Learning Conference},
  shortname={NLDL},
  year={2025},
  editor={Lutchyn, Tetiana and Ram\'irez Rivera, Ad\'in and Ricaud, Benjamin},
  publisher={PMLR},
  series={Proceedings of Machine Learning Research},
  volume={265},
  start={2025-01-07},
  end={2025-01-09},
  published = {2025-01-12},
  address={UiT The Arctic University, Troms\o, Norway},
  conference_url={https://www.nldl.org},
  conference_number={6}
}


@inproceedings{arteaga2025,
title={Hallucination Detection in {LLM}s: Fast and Memory-Efficient Finetuned Models},
author={Arteaga, Gabriel Y. and Sch{\"o}n, Thomas B. and Pielawski, Nicolas},
openreview={8T8QkDsuO9},
software={https://github.com/Gabriel-Arteaga/LLM-Ensemble},
abstract={Uncertainty estimation is a necessary component when implementing AI in high-risk settings, such as autonomous cars, medicine, or insurances. Large Language Models (LLMs) have seen a surge in popularity in recent years, but they are subject to hallucinations, which may cause serious harm in high-risk settings. Despite their success, LLMs are expensive to train and run: they need a large amount of computations and memory, preventing the use of ensembling methods in practice. In this work, we present a novel method that allows for fast and memory-friendly training of LLM ensembles. We show that the resulting ensembles can detect hallucinations and are a viable approach in practice as only one GPU is needed for training and inference.},
pages={1--15}
}

@inproceedings{brusch2025,
title={Freq{RISE}: Explaining time series using frequency masking},
author={Br{\"u}sch, Thea and Wickstr{\o}m, Kristoffer Knutsen and Schmidt, Mikkel N. and Alstr{\o}m, Tommy Sonne and Jenssen, Robert},
openreview={JBH3mtjG9I},
software={https://github.com/theabrusch/FreqRISE},
abstract={Time series data is fundamentally important for many critical domains such as healthcare, finance, and climate, where explainable models are necessary for safe automated decision-making. To develop explainable artificial intelligence in these domains therefore implies explaining salient information in the time series. Current methods for obtaining saliency maps assumes localized information in the raw input space. In this paper, we argue that the salient information of a number of time series is more likely to be localized in the frequency domain. We propose FreqRISE, which uses masking based methods to produce explanations in the frequency and time-frequency domain, and outperforms strong baselines across a number of tasks.},
pages={16--31}
}

@inproceedings{debner2025,
title={Towards concurrent real-time audio-aware agents with deep reinforcement learning},
author={Debner, Anton and Hirvisalo, Vesa},
openreview={UQuETmoMQX},
software={https://github.com/Aalto-ESG/aaaa-2025},
abstract={Audio holds significant amount of information about our surroundings. It can be used to navigate, assess threats, communicate, as a source of curiosity, and to separate the sources of different sounds. Still, these rich properties of audio are not fully utilized by current video game agents. 

We use spatial audio libraries in combination with deep reinforcement learning to allow agents to observe their surroundings and to navigate in their environment using audio cues. In general, game engines support rendering audio for one agent only. Using a hide-and-seek scenario in our experimentation we show how support for multiple concurrent listeners can be used to parallelize the runtime operation and to enable using multiple agents. Further, we analyze the effects of audio environment complexity to demonstrate the scalability of our approach.},
pages={32--40}
}

@inproceedings{dorszewski2025,
title={Connecting Concept Convexity and Human-Machine Alignment in Deep Neural Networks},
author={Dorszewski, Teresa and T{\v{e}}tkov{\'a}, Lenka and Linhardt, Lorenz and Hansen, Lars Kai},
openreview={e1dpokhi0c},
abstract={Understanding how neural networks align with human cognitive processes is a crucial step toward developing more interpretable and reliable AI systems. Motivated by theories of human cognition, this study examines the relationship between convexity in neural network representations and human-machine alignment based on behavioral data. We identify a correlation between these two dimensions in pretrained and fine-tuned vision transformer models. Our findings suggest the convex regions formed in latent spaces of neural networks to some extent align with human-defined categories and reflect the similarity relations humans use in cognitive tasks. While optimizing for alignment generally enhances convexity, increasing convexity through fine-tuning yields inconsistent effects on alignment, which suggests a complex relationship between the two. This study presents a first step toward understanding the relationship between the convexity of latent representations and human-machine alignment.},
pages={41--50}
}

@inproceedings{eide2025,
title={Bo{RA}: Bayesian Hierarchical Low-Rank Adaption for Multi-task Large Language Models},
author={Eide, Simen and Frigessi, Arnoldo},
openreview={bkQRCWYrMb},
software={https://github.com/simeneide/bora},
abstract={This paper introduces Bayesian Hierarchical Low-Rank Adaption (BoRA), a novel method for finetuning multi-task Large Language Models (LLMs). Current finetuning approaches, such as Low-Rank Adaption (LoRA), perform exeptionally well in reducing training parameters and memory usage but face limitations when applied to multiple similar tasks. Practitioners usually have to choose between training separate models for each task or a single model for all tasks, both of which come with trade-offs in specialization and data utilization.

BoRA addresses these trade-offs by leveraging a Bayesian hierarchical model that allows tasks to share information through global hierarchical priors. This enables tasks with limited data to benefit from the overall structure derived from related tasks while allowing tasks with more data to specialize. Our experimental results show that BoRA outperforms both individual and unified model approaches, achieving lower perplexity and better generalization across tasks. This method provides a scalable and efficient solution for multi-task LLM finetuning, with significant practical implications for diverse applications.},
pages={51--57}
}

@inproceedings{enevoldsen2025,
title={Familiarity-Based Open-Set Recognition Under Adversarial Attacks},
author={Enevoldsen, Philip and Gundersen, Christian and Lang, Nico and Belongie, Serge and Igel, Christian},
openreview={14ptPJP6fG},
abstract={Open-set recognition (OSR), the identification of novel categories, can be a critical component when deploying classification models in real-world applications. Recent work has shown that familiarity-based scoring rules such as the Maximum Softmax Probability (MSP) or the Maximum Logit Score (MLS) are strong baselines when the closed-set accuracy is high. However, one of the potential weaknesses of familiarity-based OSR are adversarial attacks. Here, we study gradient-based adversarial attacks on familiarity scores for both types of attacks, False Familiarity and False Novelty attacks, and evaluate their effectiveness in informed and uninformed settings on TinyImageNet. Furthermore, we explore how novel and familiar samples react to adversarial attacks and formulate the adversarial reaction score as an alternative OSR scoring rule, which shows a high correlation with the MLS familiarity score.},
pages={58--65}
}

@inproceedings{ferrao2025,
title={World Model Agents with Change-Based Intrinsic Motivation},
author={Ferrao, Jeremias Lino and Cunha, Rafael F.},
openreview={0io7gvXniL},
software={https://github.com/Jazhyc/world-model-policy-transfer},
abstract={Sparse reward environments pose a significant challenge for reinforcement learning due to the scarcity of feedback. Intrinsic motivation and transfer learning have emerged as promising strategies to address this issue. Change Based Exploration Transfer (CBET), a technique that combines these two approaches for model-free algorithms, has shown potential in addressing sparse feedback but its effectiveness with modern algorithms remains understudied. This paper provides an adaptation of CBET for world model algorithms like DreamerV3 and compares the performance of DreamerV3 and IMPALA agents, both with and without CBET, in the sparse reward environments of Crafter and Minigrid. Our tabula rasa results highlight the possibility of CBET improving DreamerV3's returns in Crafter but the algorithm attains a suboptimal policy in Minigrid with CBET further reducing returns. In the same vein, our transfer learning experiments show that pre-training DreamerV3 with intrinsic rewards does not immediately lead to a policy that maximizes extrinsic rewards in Minigrid. Overall, our results suggest that CBET provides a positive impact on DreamerV3 in more complex environments like Crafter but may be detrimental in environments like Minigrid. In the latter case, the behaviours promoted by CBET in DreamerV3 may not align with the task objectives of the environment, leading to reduced returns and suboptimal policies.},
pages={66--74}
}

@inproceedings{hansen2025,
title={Graph Counterfactual Explainable {AI} via Latent Space Traversal},
author={Hansen, Andreas Abildtrup and Pegios, Paraskevas and Calissano, Anna and Feragen, Aasa},
openreview={Pyqnc9eWhB},
abstract={Explaining the predictions of a deep neural network is a nontrivial task, yet high-quality explanations for predictions are often a prerequisite for practitioners to trust these models. \textit{Counterfactual explanations} aim to explain predictions by finding the ``nearest'' in-distribution alternative input whose prediction changes in a pre-specified way. However, it remains an open question how to define this nearest alternative input, whose solution depends on both the domain (e.g. images, graphs, tabular data, etc.) and the specific application considered. For graphs, this problem is complicated i) by their discrete nature, as opposed to the continuous nature of state-of-the-art graph classifiers; and ii) by the node permutation group acting on the graphs. We propose a method to generate counterfactual explanations for any differentiable black-box graph classifier, utilizing a case-specific permutation equivariant graph variational autoencoder. We generate counterfactual explanations in a continuous fashion by traversing the latent space of the autoencoder across the classification boundary of the classifier, allowing for seamless integration of discrete graph structure and continuous graph attributes. We empirically validate the approach on three graph datasets, showing that our model is consistently high performing and more robust than the baselines.},
pages={75--84}
}

@inproceedings{hausner2025,
title={Learning incomplete factorization preconditioners for {GMRES}},
author={H{\"a}usner, Paul and Juscafresa, Aleix Nieto and Sj{\"o}lund, Jens},
openreview={ZF64XEUgHm},
software={https://github.com/paulhausner/neural-incomplete-factorization},
abstract={Incomplete LU factorizations of sparse matrices are widely used as preconditioners in Krylov subspace methods to speed up solving linear systems. Unfortunately, computing the preconditioner itself can be time-consuming and sensitive to hyper-parameters. Instead, we replace the hand-engineered algorithm with a graph neural network that is trained to approximate the matrix factorization directly. To apply the output of the neural network as a preconditioner, we propose an output activation function that guarantees that the predicted factorization is invertible. Further, applying a graph neural network architecture allows us to ensure that the output itself is sparse which is desirable from a computational standpoint. We theoretically analyze and empirically evaluate different loss functions to train the learned preconditioners and show their effectiveness in decreasing the number of GMRES iterations and improving the spectral properties on synthetic data. The code is available at https://github.com/paulhausner/neural-incomplete-factorization.},
pages={85--99}
}

@inproceedings{healy2025,
title={Enhancing Fault Detection in Optical Networks with Conditional Denoising Diffusion Probabilistic Models},
author={Healy, Meadhbh and J{\o}rgensen, Thomas Martini},
openreview={Bkm9j80WTj},
abstract={The scarcity of high-quality anomalous data often poses a challenge in establishing effective automated fault detection schemes. This study addresses the issue in the context of fault detection in optical fibers using reflectometry data, where noise can obscure the detection of certain known anomalies. We specifically investigate whether classes containing samples of low quality can be boosted with synthetically generated examples characterized by high signal-to-noise ratio (SNR). Specifically, we employ a conditional Denoising Diffusion Probabilistic Model (cDDPM) to generate synthetic data for such classes. It works by learning the characteristics of high SNRs from anomaly classes that are less frequently affected by significant noise. The boosted dataset is compared with a baseline dataset (without the augmented data) by   training an anomaly classifier and measuring the performances on a hold-out dataset populated only with high quality traces for all classes. We observe a significant improved performance (Precision, Recall, and F1 Scores) for the noise affected training classes proving the success of our methods.},
pages={100--109}
}

@inproceedings{jain2025,
title={One-Class {SVM}-guided Negative Sampling for Enhanced Contrastive Learning},
author={Jain, Dhruv and Mayet, Tsiry and H{\'E}RAULT, Romain and MODZELEWSKI, Romain},
openreview={XCUzATsVdU},
software={https://github.com/DJ-CHB/MiOC-Official},
abstract={Recent studies on contrastive learning have emphasized carefully sampling and mixing negative samples.
This study introduces a novel and improved approach for generating synthetic negatives.
We propose a new method using One-Class Support Vector Machine (OCSVM) to guide in the selection process before mixing named as  **Mixing OCSVM negatives (MiOC)**.
Our results show that our approach creates more meaningful embeddings, which lead to better classification performance.
We implement our method using publicly available datasets (Imagenet100, Cifar10, Cifar100, Cinic10, and STL10). We observed that MiOC exhibit favorable performance compared to state-of-the-art methods across these datasets.
 By presenting a novel approach, this study emphasizes the exploration of alternative mixing techniques that expand the sampling space beyond the conventional confines of hard negatives produced by the ranking of the dot product.},
pages={110--119}
}

@inproceedings{jensen2025,
title={Deep Active Latent Surfaces for Medical Geometries},
author={Jensen, Patrick M{\o}ller and Wickramasinghe, Udaranga and Dahl, Anders and Fua, Pascal and Dahl, Vedrana Andersen},
openreview={TP0ASAlrp2},
abstract={Shape priors have long been known to be effective when reconstructing 3D shapes from noisy or incomplete data.  When using a deep-learning based shape representation, this often involves learning a latent representation, which can be either in the form of a single global vector or of multiple local ones. The latter allows more flexibility but is prone to overfitting. 
In this paper, we advocate a hybrid approach representing shapes in terms of 3D meshes with a separate latent vector at each vertex. During training the latent vectors are constrained to have the same value, which avoids overfitting. For inference, the latent vectors are updated independently while imposing spatial regularization constraints. We show that this gives us both flexibility and generalization capabilities, which we demonstrate on several medical image processing tasks.},
pages={120--132}
}

@inproceedings{johnsen2025,
title={{SPARDACUS} SafetyCage: A new misclassification detector},
author={Johnsen, P{\r{a}}l Vegard and Remonato, Filippo and Benedict, Shawn and Ndur-Osei, Albert},
openreview={3FswRo4Lhj},
abstract={Given the increasing adoption of machine learning techniques in society and industry, it is important to put procedures in place that can infer and signal whether the prediction of an ML model may be unreliable.
This is not only relevant for ML specialists, but also for laypersons who may be end-users.
In this work, we present a new method for flagging possible misclassifications from a feed-forward neural network in a general multi-class problem, called SPARDA-enabled Classification Uncertainty Scorer (SPARDACUS).
For each class and layer, the probability distribution functions of the activations for both correctly and wrongly classified samples are recorded.
Using a Sparse Difference Analysis (SPARDA) approach, an optimal projection along the direction maximizing the Wasserstein distance enables $p$-value computations to confirm or reject the class prediction.
Importantly, while most existing methods act on the output layer only, our method can in addition be applied on the hidden layers in the neural network, thus being useful in applications, such as feature extraction, that necessarily exploit the intermediate (hidden) layers.
We test our method on both a well-performing and under-performing classifier, on different datasets, and compare with other previously published approaches.
Notably, while achieving performance on par with two state-of-the-art-level methods, we significantly extend in flexibility and applicability.
We further find, for the models and datasets chosen, that the output layer is indeed the most valuable for misclassification detection, and adding information from previous layers does not necessarily improve performance in such cases.},
pages={133--140}
}

@inproceedings{lende2025,
title={Interpretable Function Approximation with Gaussian Processes in Value-Based Model-Free Reinforcement Learning},
author={Lende, Matthijs van der and Sabatelli, Matthia and Cardenas-Cartagena, Juan},
openreview={QswzbrMy3R},
software={https://github.com/matthjs/BachelorProject},
abstract={Estimating value functions in Reinforcement Learning (RL) for continuous spaces is challenging. While traditional function approximators, such as linear models, offer interpretability, they are limited in their complexity. In contrast, deep neural networks can model more complex functions but are less interpretable. Gaussian Process (GP) models bridge this gap by offering interpretable uncertainty estimates while modeling complex nonlinear functions. This work introduces a Bayesian nonparametric framework using GPs, including Sparse Variational (SVGP) and Deep GPs (DGP), for off-policy and on-policy learning. Results on popular classic control environments show that SVGPs/DGPs outperform linear models but converge slower than their neural network counterparts. Nevertheless, they do provide valuable insights when it comes to uncertainty estimation and interpretability for RL.},
pages={141--154}
}

@inproceedings{machnio2025,
title={Deep Learning for Localization of White Matter Lesions in Neurological Diseases},
author={Machnio, Julia and Nielsen, Mads and Ghazi, Mostafa Mehdipour},
openreview={ea0YJaJShO},
software={https://github.com/juliamachnio/WMHLocalization},
abstract={White Matter (WM) lesions, commonly observed as hyperintensities on FLAIR MRIs or hypointensities on T1-weighted images, are associated with neurological diseases. The spatial distribution of these lesions is linked to an increased risk of developing neurological conditions, emphasizing the need for location-based analyses. Traditional manual identification and localization of WM lesions are labor-intensive and time-consuming, highlighting the need for automated solutions. In this study, we propose novel deep learning-based methods for automated WM lesion segmentation and localization. Our approach utilizes state-of-the-art models to concurrently segment WM lesions and anatomical WM regions, providing detailed insights into their distribution within the brain's anatomical structure. By applying k-means clustering to the regional WM lesion load, distinct subject groups are identified to be associated with various neurological conditions, validating the method's alignment with established clinical findings. The robustness and adaptability of our method across different scanner types and imaging protocols make it a valuable tool for research and clinical practice, offering potential improvements in diagnostic efficiency and patient care.},
pages={155--167}
}

@inproceedings{menden2025,
title={Bounds on the Generalization Error in Active Learning},
author={Menden, Vincent and Saleh, Yahya and Iske, Armin},
openreview={KcBMGkip79},
abstract={We establish empirical risk minimization principles for active learning by 
deriving a family of upper bounds on the generalization error. Aligning with empirical observations, the bounds suggest that superior query algorithms can be obtained by
combining both informativeness and representativeness query strategies, where the latter is assessed using integral probability metrics.
 To facilitate the use of these bounds in
application, we systematically link diverse active
learning scenarios, characterized by their loss functions and hypothesis
classes to their corresponding upper bounds. Our results show that
regularization techniques used to constraint the complexity of various hypothesis
classes are sufficient conditions to ensure the validity of the bounds.
The present work enables principled
construction and empirical quality-evaluation of query algorithms in active learning.},
pages={168--175}
}

@inproceedings{mimouni2025,
title={Deep Q-Learning with Whittle Index for Contextual Restless Bandits: Application to Email Recommender Systems},
author={Mimouni, Ibtihal El and Avrachenkov, Konstantin},
openreview={alnaQJdBNs},
abstract={In this paper, we introduce DQWIC, a novel algorithm that combines Deep Reinforcement Learning and Whittle index theory within the Contextual Restless Multi-Armed Bandit framework for the discounted criterion. DQWIC is designed to learn in evolving environments typical of real-world applications, such as recommender systems, where  user preferences and environmental dynamics evolve over time. In particular, we apply DQWIC to the problem of optimizing email recommendations, where it tackles the dual challenges of enhancing content relevance and reducing spam messages, thereby addressing ethical concerns related to intrusive emailing. The algorithm leverages two neural networks: a Q-network for approximating action-value functions and a Whittle-network for estimating Whittle indices, both of which integrate contextual features to inform decision-making. In addition, the inclusion of context allows us to handle many heterogeneous users in a scalable way. The learning process occurs through a two time scale stochastic approximation, with the Q-network updated frequently to minimize the loss between predicted and target Q-values, and the Whittle-network updated on a slower time scale. To evaluate its effectiveness, we conducted experiments in partnership with a company specializing in digital marketing. Our results, derived from both synthetic and real-world data, show that DQWIC outperforms existing email marketing baselines.},
pages={176--183}
}

@inproceedings{moller2025,
title={{NEM}t: Fast Targeted Explanations for Medical Image Models via Neural Explanation Masks},
author={M{\o}ller, Bj{\o}rn Leth and Amiri, Sepideh and Igel, Christian and Wickstr{\o}m, Kristoffer Knutsen and Jenssen, Robert and Keicher, Matthias and Azampour, Mohammad Farid and Navab, Nassir and Ibragimov, Bulat},
openreview={PenPJYfmaA},
abstract={A fundamental barrier to the adoption of AI systems in clinical practice is the insufficient transparency of AI decision-making. The field of Explainable Artificial Intelligence (XAI) seeks to provide human-interpretable explanations for a given AI model. The recently proposed Neural Explanation Mask (NEM) framework is the first XAI method to explain learned representations with high accuracy at real-time speed. 
NEM transforms a given differentiable model into a self-explaining system by augmenting it with a neural network-based explanation module. This module is trained in an unsupervised manner to output occlusion-based explanations for the original model. However, the current framework does not consider labels associated with the inputs. This makes it unsuitable for many important tasks in the medical domain that require explanations specific to particular output dimensions, such as pathology discovery, disease severity regression, and multi-label data classification.
In this work, we address this issue by introducing a loss function for training explanation modules incorporating labels. It steers explanations toward target labels alongside an integrated smoothing operator, which reduces artifacts in the explanation masks. We validate the resulting  Neural Explanation Masks with target labels (NEMt) framework on public databases of lung radiographs and skin images. The obtained results are superior to the state-of-the-art XAI methods in terms of explanation relevancy mass, complexity, and sparseness. Moreover, the explanation generation is several hundred times faster, allowing for real-time clinical applications. The code is publicly available at https://github.com/baerminator/NEM_T},
pages={184--192}
}

@inproceedings{mukhopadhyay2025,
title={Transformers at a fraction},
author={Mukhopadhyay, Aritra and Joshi, Rucha Bhalchandra and Tiwari, Nidhi and Mishra, Subhankar},
openreview={1U0kkt7ymn},
abstract={Transformer-based large models, such as GPT, are known for their performance and ability to effectively address tasks. Transformer-based models often have many parameters, which are trained to achieve high-performance levels. As a result, they cannot be run locally on devices with smaller memory sizes, such as mobile phones, necessitating the use of these models remotely by sending the data to the cloud. This exposes us to privacy concerns over sending confidential data to the server, among others. In this work, we propose a method to make these large models easier to run on devices with much smaller memory while sacrificing little to no performance. We investigate quaternion neural networks, which can reduce the number of parameters to one-fourth of the original real-valued model when employed efficiently. Additionally, we explore sparse networks created by pruning weights as a method of parameter reduction, following the Lottery Ticket Hypothesis.

We perform the experiments on vision and language tasks on their respective datasets. We observe that pruned quaternion models perform better than the real-valued models in severely sparse conditions.},
pages={193--203}
}

@inproceedings{rajeev2025,
title={Predicting Oligomeric states of Fluorescent Proteins using Mamba},
author={Rajeev, Agney K and B, Joel Joseph K and Mishra, Subhankar},
openreview={KaZzDtUeJY},
software={https://github.com/smlab-niser/FluorMamba},
abstract={Fluorescent proteins (FPs) are essential tools in biomedical imaging, known for their ability to absorb and emit light, thereby allowing visualization of biological processes. Understanding the oligomeric state is crucial, as monomeric forms are often preferred in applications to minimize potential artifacts and prevent interference with cellular functions. Experimental methods to find the oligomeric state can be time-consuming and expensive. Most of the current computational model is CPU-based, limiting their speed and scalability. This paper studies the effectiveness of GPU-based deep-learning models in predicting the oligomeric states of fluorescent proteins directly from their amino acid sequences, specifically focusing on the Mamba architecture. Various protein-specific augmentations were also employed to enhance the model's generalizability. Our results indicate that the mamba-based model achieves accuracy and F1 score close to 90\% and an MCC value of 0.8 with in predicting the oligomeric states of fluorescent proteins directly from its amino acid sequence. The code used in this study is available at [GitHub repository](https://github.com/smlab-niser/FluorMamba).},
pages={204--212}
}

@inproceedings{rozanec2025,
title={Learning anomalies from graph: predicting compute node failures on {HPC} clusters},
author={Rozanec, Joze M. and Krumpak, Roy and Molan, Martin and Bartolini, Andrea},
openreview={SPRdfOkuHw},
abstract={Today, high-performance computing (HPC) systems play a crucial role in advancing artificial intelligence. Nevertheless, the estimated global data center electricity consumption in 2022 was around 1\% of the final global electricity demand. Therefore, as HPC systems advance towards Exascale computing, research is required to ensure their growth is sustainable and environmentally friendly. Data from infrastructure monitoring can be leveraged to predict downtimes, ensure these are treated in time, and increase the overall system's utilization. In this paper, we compare four machine-learning approaches, three of them based on graph embeddings, to predict compute node downtimes. The experiments were performed with data from Marconi 100, a tier-0 production supercomputer at CINECA in Bologna, Italy. Our results show that the machine learning models can accurately predict downtime, matching current state-of-the-art models.},
pages={213--219}
}

@inproceedings{selvan2025,
title={Pe{PR}: Performance Per Resource Unit as a Metric to Promote Small-scale Deep Learning},
author={Selvan, Raghavendra and Pepin, Bob and Igel, Christian and Samuel, Gabrielle and Dam, Erik B},
openreview={Pb47B5t0pr},
software={https://github.com/saintslab/PePR},
abstract={The recent advances in deep learning (DL) have been accelerated by access to large-scale data and compute. These large-scale resources have been used to train progressively larger models which are resource intensive in terms of compute, data, energy, and carbon emissions. These costs are becoming a new type of entry barrier to researchers and practitioners with limited access to resources at such scale, particularly in the Global South. In this work, we take a comprehensive look at the landscape of existing DL models for medical image analysis tasks and demonstrate their usefulness in settings where resources are limited. To account for the resource consumption of DL models, we introduce a novel measure to estimate the performance per resource unit, which we call the PePR score. Using a diverse family of 131 unique DL architectures (spanning $1M$ to $130M$ trainable parameters) and three medical image datasets, we capture trends about the performance-resource trade-offs. In applications like medical image analysis, we argue that small-scale, specialized  models are better than striving for large-scale models. Furthermore, we show that using existing pretrained models that are fine-tuned on new data can significantly reduce the computational resources and data required compared to training models from scratch. We hope this work will encourage the community to focus on improving AI equity by developing methods and models with smaller resource footprints.},
pages={220--229}
}

@inproceedings{sinhamahapatra2025,
title={Zero-Shot Open-Vocabulary {OOD} Object Detection and Grounding using Vision Language Models},
author={Sinhamahapatra, Poulami and Bose, Shirsha and Roscher, Karsten and G{\"u}nnemann, Stephan},
openreview={Q2wVVeOpz8},
abstract={Automated driving involves complex perception tasks that require a precise understanding of diverse traffic scenarios and confident navigation. Traditional data-driven algorithms trained on closed-set data often fail to generalize upon out-of-distribution (OOD) and edge cases. Recently, Large Vision Language Models (LVLMs) have shown potential in integrating the reasoning capabilities of language
models to understand and reason about complex driving scenes, aiding generalization to OOD scenarios. However, grounding such OOD objects still remains a challenging task. In this work, we propose an automated framework zPROD, for zero-shot promptable open vocabulary OOD object detection, segmentation, and grounding in autonomous driving. We leverage LVLMs with visual grounding capabilities, eliminating the need for lengthy text communication and providing precise indications of OOD objects in the scene or on the track of the ego-centric vehicle. We evaluate our approach on OOD datasets from existing road anomaly segmentation benchmarks such as SMIYC and Fishyscapes. Our zero-shot approach shows superior performance on RoadAnomaly and RoadObstacle and comparable results on the Fishyscapes subset as compared to supervised models and acts a baseline for future zero-shot methods based on open vocabulary OOD detection.},
pages={230--238}
}

@inproceedings{sporring2025,
title={Locally orderless networks},
author={Sporring, Jon and Xu, Peidi and Lu, Jiahao and Lauze, Francois Bernard and Darkner, Sune},
openreview={JNxddbPPWt},
abstract={We present Locally Orderless Networks (LON) and the theoretical foundation that links them to Convolutional Neural Networks (CNN), Scale-space histograms, and measurement theory. The key elements are a regular sampling of the bias and the derivative of the activation function. We compare LON, CNN, and Scale-space histograms on prototypical single-layer networks. We show how LON and CNN can emulate each other and how LON expands the set of functions computable to non-linear functions such as squaring. We demonstrate simple networks that illustrate the improved performance of LON over CNN on simple tasks for estimating the gradient magnitude squared, for regressing shape area and perimeter lengths, and for explainability of individual pixels' influence on the result.},
pages={239--244}
}

@inproceedings{uebbing2025,
title={Investigating the Impact of Feature Reduction for Deep Learning-based Seasonal Sea Ice Forecasting},
author={Uebbing, Lars and Joakimsen, Harald Lykke and Luppino, Luigi Tommaso and Martinsen, Iver and McDonald, Andrew and Wickstr{\o}m, Kristoffer Knutsen and Lef{\`e}vre, S{\'e}bastien and Salberg, Arnt B. and Hosking, Scott and Jenssen, Robert},
openreview={7TwvcPAyxX},
abstract={With the state-of-the-art IceNet model, deep learning has contributed to an important aspect of climate research by leveraging a range of climate inputs to provide accurate forecasts of Arctic sea ice concentration (SIC).
The deep learning subfield of eXplainable AI (XAI) has gained enormous attention in order to gauge feature importance of neural networks, for instance by leveraging network gradients.
In recent work, an XAI study of the IceNet was conducted, using gradient saliency maps to interrogate its feature importance.
A majority of XAI studies provide information about feature importance as revealed by the XAI method, but rarely provide thorough analysis of effects from reducing the number of input variables. 
In this paper, we train versions of the IceNet with drastically reduced numbers of input features according to results of XAI and investigate the effects on the sea ice predictions, on average and with respect to specific events.
Our results provide evidence that the model generally performs better when less features are used, but in case of anomalous events, a larger number of features is beneficial.
We believe our thorough study of the IceNet in terms of feature importance revealed by XAI may give inspiration for other deep learning-based problem scenarios and application domains.},
pages={245--254}
}

@inproceedings{wallace2025,
title={Exploring Segment Anything Foundation Models for Out of Domain Crevasse Drone Image Segmentation},
author={Wallace, Steven and Durrant, Aiden and Harcourt, William David and Hann, Richard and Leontidis, Georgios},
openreview={CGkyjTXomz},
abstract={In this paper, we explore the application of Segment Anything (SAM) foundation models for segmenting crevasses in Uncrewed Aerial Vehicle (UAV) images of glaciers. We evaluate the performance of the SAM and SAM 2 models on ten high-resolution UAV images from Svalbard, Norway. Each SAM model has been evaluated in inference mode without additional fine-tuning. Using both automated and manual prompting methods, we compare the segmentation quantitatively using Dice Score Coefficient (DSC) and Intersection over Union (IoU) metrics. Results show that the SAM 2 Hiera-L model outperforms other variants, achieving average DSC and IoU scores of 0.43 and 0.28 respectively with automated prompting. However, the overall off-the-shelf performance suggests that further improvements are still required to enable glaciologists to examine crevasse patterns and associated physical processes (e.g. iceberg calving), indicating the need for further fine-tuning to address domain shift challenges. Our results highlight the potential of segmentation foundation models for specialised remote sensing applications while also identifying limitations in applying them to high-resolution UAV images, as well as ways to enhance further model performance on out-of-domain glacier imagery, such as few-shot and weakly supervised learning techniques.},
pages={255--268}
}

@inproceedings{wohlstein2025,
title={Toward Learning Distributions of Distributions},
author={Wohlstein, Moritz and Brefeld, Ulf},
openreview={rIQCKH0He8},
abstract={We propose a novel generative deep learning architecture based on generative moment matching networks. The objective of our model is to learn a distribution over distributions and generate new sample distributions following the (possibly complex) distribution of training data. We derive a custom loss function for our model based on the maximum mean discrepancy test. Our model is evaluated on different datasets where we investigate the influence of hyperparameters on performance.},
pages={269--275}
}

