---
title: 'BoRA: Bayesian Hierarchical Low-Rank Adaption for Multi-task Large Language
  Models'
openreview: bkQRCWYrMb
software: https://github.com/simeneide/bora
abstract: This paper introduces Bayesian Hierarchical Low-Rank Adaption (BoRA), a
  novel method for finetuning multi-task Large Language Models (LLMs). Current finetuning
  approaches, such as Low-Rank Adaption (LoRA), perform exeptionally well in reducing
  training parameters and memory usage but face limitations when applied to multiple
  similar tasks. Practitioners usually have to choose between training separate models
  for each task or a single model for all tasks, both of which come with trade-offs
  in specialization and data utilization. BoRA addresses these trade-offs by leveraging
  a Bayesian hierarchical model that allows tasks to share information through global
  hierarchical priors. This enables tasks with limited data to benefit from the overall
  structure derived from related tasks while allowing tasks with more data to specialize.
  Our experimental results show that BoRA outperforms both individual and unified
  model approaches, achieving lower perplexity and better generalization across tasks.
  This method provides a scalable and efficient solution for multi-task LLM finetuning,
  with significant practical implications for diverse applications.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: eide25a
month: 0
tex_title: 'Bo{RA}: Bayesian Hierarchical Low-Rank Adaption for Multi-task Large Language
  Models'
firstpage: 51
lastpage: 57
page: 51-57
order: 51
cycles: false
bibtex_author: Eide, Simen and Frigessi, Arnoldo
author:
- given: Simen
  family: Eide
- given: Arnoldo
  family: Frigessi
date: 2025-01-12
address:
container-title: Proceedings of the 6th Northern Lights Deep Learning Conference (NLDL)
volume: '265'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 1
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v265/main/assets/eide25a/eide25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
